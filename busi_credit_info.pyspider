#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on 2017-08-01 09:15:49
# Project: cnwood

from pyspider.libs.base_handler import *
from pyspider.database.mysql.mysqldb import MySql
from urllib import parse
import hashlib

class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    def on_start(self):
        self.crawl('http://www.cnwood.org/a/xinwenzixun/xiehuiyaowen/', callback=self.index_page)

    @config(age=10 * 24 * 60 * 60)
    def index_page(self, response):
        for each in response.doc('.dede_pages > a').items():
            self.crawl(each.attr.href, callback=self.index_page)
        for each in response.doc('.nr2 a').items():
            self.crawl(each.attr.href, callback=self.detail_page)
            

    @config(priority=2)
    def detail_page(self, response):
        urls = response.url
        title = response.doc('h1').text()
        pagekey = self.getmd5(title+urls)
        return {
            "pagekey": pagekey,
            "urls": urls,
            "title": title,
            "content":response.doc('.nr9').text()
            "sites":"http://www.cnwood.org" 
            "kinds":"010101"
        }
    
    def getmd5(self,value):
        m = hashlib.md5()
        m.update(value.encode("utf8"))
        return m.hexdigest()
    
    def on_result(self, result):
        #print result
        if not result or not result['title']:
            return
        sql = MySql()
        sql.into('BUSI_CREDIT_INFO',**result)
