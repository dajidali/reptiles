#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on 2017-08-31 10:24:23
# Project: 26_oil_explor

from pyspider.libs.base_handler import *
from pyspider.database.mysql.mysqldb import MySql
import pyspider.libs.xxtools as tools
import time

class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    def on_start(self):
        urls=[
            ['http://www.ccesda.com/webhtml/syxh/List/List_1913.html','0260101'],#	部委动态
            ['http://www.ccesda.com/webhtml/syxh/List/List_1625.html','0260102'],#	协会动态
            ['http://www.ccesda.com/webhtml/syxh/List/List_1627.html','0260103'],#	会员动态
            ['http://www.ccesda.com/webhtml/syxh/List/List_1591.html','0260201'],#	勘察设计
            ['http://www.ccesda.com/webhtml/syxh/List/List_1616.html','0260202'],#	项目管理
            ['http://www.ccesda.com/webhtml/syxh/List/List_1608.html','0260203'],#	执业注册
            ['http://www.ccesda.com/webhtml/syxh/List/List_1906.html','0260204'],#	容器管道
        ]        
        for each in urls:
            self.crawl(each[0], callback=self.index_page, save=each[1])
        #self.crawl('http://www.ccesda.com/webhtml/syxh/List/List_1588.html', callback=self.index_page, save = '0260101')

    @config(age=10 * 24 * 60 * 60)
    def index_page(self, response):
        for each in response.doc('.td-zhen td td td > a').items():
            if(len(each.text())<5):
                self.crawl(each.attr.href, callback=self.index_page, save = response.save)
            elif(each.attr.href.find('.html')>0 and each.attr.href.find('ccesda.com')>0):
                self.crawl(each.attr.href, callback=self.detail_page, save = response.save)
               

    @config(priority=2)
    def detail_page(self, response):
        str_title = response.doc('body > table.biankuang03 > tbody > tr > td > table:nth-child(1) > tbody > tr > td:nth-child(2) > table > tbody > tr > td').text()
        title = str_title[str_title.rfind(">")+7:len(str_title)]

        content = response.doc('#zoom').html()
        url = response.url
        site = 'http://www.ccesda.com/'
        content_dom = tools.ext_cont(url, content)
        pagekey = tools.get_md5(title+url)
        date_string = response.doc('body > table.biankuang03 > tbody > tr > td > table:nth-child(3) > tbody > tr > td:nth-child(2) > table > tbody > tr > td:nth-child(2)').text()

        date = time.strptime(date_string,'%Y-%m-%d')
        date = time.strftime('%Y%m%d',date)        
        kind = response.save
        return {
            "pagekey": pagekey,
            "url": url,
            "site": site,
            "title": title,
            "content_dom":content_dom,
            "cdate": date,
            "kind":kind
        }

    def on_result(self, result):
        print(result)
        if not result or not result['title']:
            return
        sql = MySql()
        sql.into('BUSI_CREDIT_INFO',**result)    
