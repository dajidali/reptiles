#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on 2017-08-04 00:44:17
# Project: cmepca


from pyspider.libs.base_handler import *
from pyspider.database.mysql.mysqldb import MySql
import pyspider.libs.xxtools as tools
import urllib
from urllib import parse


class Handler(BaseHandler):
    def on_start(self):
        #新闻中心
        self.crawl('http://www.cmepca.org.cn/newslist.asp?id=6',callback=self.phantomjs_parser , fetch_type='js' ,params={'crkind': '100101'} ) #行业资讯
        self.crawl('http://www.cmepca.org.cn/newslist.asp?id=7',callback=self.phantomjs_parser , fetch_type='js' ,params={'crkind': '100102'} ) #工作动态
        self.crawl('http://www.cmepca.org.cn/newslist.asp?id=8',callback=self.phantomjs_parser , fetch_type='js' ,params={'crkind': '100103'} ) #政策导向
        #认证企业
        self.crawl('http://www.cmepca.org.cn/renzheng/',callback=self.phantomjs_parser , fetch_type='js' ,params={'crkind': '100201'} ) #信用认证
        #会议展览
        self.crawl('http://www.cmepca.org.cn/meeting/',callback=self.phantomjs_parser , fetch_type='js' ,params={'crkind': '100301'} ) #会议展览

    @config(age=0)
    def phantomjs_parser(self, response):
        qs1 = parse.parse_qs(list(parse.urlparse(response.url))[4])#从上个页面获取参数crkind
        if(qs1['crkind']==['100301']):
            div='strong > a'
        else:
            div='.newslist a'     
        
        #调用detail_page函数
        for each in response.doc(div).items():
            if each not in response.doc('body > div.pbody > table:nth-child(2) > tbody > tr > td:nth-child(1) > table > tbody > tr:nth-child(22) > td a').items():
                url=each.attr.href
                #将参数crkind赋值给此页面
                bits = list(parse.urlparse(url))
                qs = parse.parse_qs(bits[4])
                qs['crkind']=qs1['crkind']
                bits[4] = parse.urlencode(qs, True)
                url = parse.urlunparse(bits)
                self.crawl(url, fetch_type='js', callback=self.detail_page)  
        #翻页
        for each in response.doc('body > div.pbody > table:nth-child(2) > tbody > tr > td:nth-child(1) > table > tbody > tr:nth-child(22) > td a').items(): 
                #if (each not in response.doc('.a1').items()):
                url=each.attr.href
                #将参数crkind赋值给此页面
                bits = list(parse.urlparse(url))
                qs = parse.parse_qs(bits[4])
                qs['crkind']=qs1['crkind']
                bits[4] = parse.urlencode(qs, True)
                url = parse.urlunparse(bits)
                self.crawl(url, fetch_type='js', callback=self.phantomjs_parser)  
       
   
    @config(priority=2)
    def detail_page(self, response):
        site = "'http://www.cmepca.org.cn/"
        url = response.url
        qs = parse.parse_qs(list(parse.urlparse(url))[4])     #从url参数字典分割出crkind的值,注意删掉'['和'''
        kind=str(qs['crkind']).strip("]").strip("[").strip("\'")   
        if(kind=='100301'):
            title = response.doc('strong').text()
            content = response.doc('body > div.pbody > table:nth-child(2) > tbody > tr > td:nth-child(1)').html()
            pagekey = tools.get_md5(title+url)
            content_dom = tools.ext_cont(url, content)
            cdate=''
        else:
            title = response.doc('h1').text()
            pagekey = tools.get_md5(title+url)
            content = response.doc('body > div.pbody > table:nth-child(2) > tbody > tr > td:nth-child(1)').html()
            content_dom = tools.ext_cont(url, content)
            #获取cdate
            i=0
            cdate=''
            info=response.doc('.tips').text()
            date=info.split('时间：')[1]
            for i in range(0,9) :
                if ( date[i] == '-'):
                     continue
                cdate=cdate+date[i]
                i+=1
        
        return {
               "pagekey": pagekey,
               "site": site,
               "url": url,
               "title":title,
               "kind": kind,
               "content":content,
               "content_dom":content_dom,
               "cdate":cdate
              }    

    
    def on_result(self, result):
        if not result or not result['title']:
            return
        sql = MySql()
        sql.into('BUSI_CREDIT_INFO',**result)



